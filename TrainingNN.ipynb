{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # creating weights. Comment out this code in case you're loading weights from file \n",
    "        # before training\n",
    "#         self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "#         self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        self.lr = learningrate\n",
    "\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "    \n",
    "    def query(self, input_list):\n",
    "        # convert input list to 2d array\n",
    "        inputs = np.array(input_list, ndmin=2).T  # Bogdan Clarify why we need to do it\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # caclucate signals into output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "\n",
    "    def train(self, input_list, targets_list):\n",
    "        # convert inputs to 2d array\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate signals of outputs\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # calculating errors (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights between input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1 - hidden_outputs)), np.transpose(inputs))\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print('====weights input hidden====')        \n",
    "        print('Size: ', self.wih.size)\n",
    "        print(len(self.wih[0]))\n",
    "        print(self.wih[0])\n",
    "        print('====weights hidden output====')\n",
    "        print('Size: ', self.who[0].size)\n",
    "        print(self.who[0])\n",
    "    \n",
    "    def save_weights_to_file(self, filename='saved_weights.npz'):\n",
    "        np.savez(filename, wih=self.wih, who=self.who)\n",
    "        print('Saved weights to file: \"{}\"'.format(filename))\n",
    "    \n",
    "    def load_weights_from_file(self, filename='saved_weights.npz'):\n",
    "        '''\n",
    "        Loads wih and who from .npz file. Loaded values are reassigned to:\n",
    "        self.wih and self.who. In this case weights would be awailable inside the class\n",
    "        '''\n",
    "        data = np.load(filename)\n",
    "        self.wih, self.who = data['wih'], data['who']\n",
    "    \n",
    "    def rotate_inputs(self, inputs, degree):\n",
    "        '''\n",
    "        Rotates inputs list to right or left, depending on degree specified\n",
    "        :param: inputs - mnist list that represents pixels of number, without first element\n",
    "        :param: degree - degree by which to turn\n",
    "        :return: flattened inputs \n",
    "        '''\n",
    "        scaled_input = inputs.reshape(28, 28)\n",
    "        inputs_rotated = scipy.ndimage.rotate(scaled_input, degree, cval=0.01, order=1, reshape=False)\n",
    "#         matplotlib.pyplot.imshow(inputs_rotated, cmap='Greys', interpolation='None')\n",
    "        inputs_flattened = inputs_rotated.flatten()\n",
    "        return inputs_flattened\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took: 109.01516819000244 seconds\n",
      "Total number of records with which we tratined NN: 180000\n"
     ]
    }
   ],
   "source": [
    "input_nodes = 784 # Because we have picture 28x28 pixels\n",
    "hidden_nodes = 250 # We can think of this number as representation of features that correspond to \n",
    "# picture of number. The more hidden_nodes more features our NN can see. If we choose smaller \"hidden_nodes\"\n",
    "# that some of features should be combined \n",
    "output_nodes = 10 # Because we have numbers from 0 to 9\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "n.load_weights_from_file('epoch5_250hidden_nodes_rotated5.npz')\n",
    "# with open('mnist_train_100.csv', 'r') as f:\n",
    "with open('mnist_train.csv', 'r') as f:\n",
    "        training_data_list = f.readlines()\n",
    "start_training_time = time.time()\n",
    "record_count = 0\n",
    "for record in training_data_list:\n",
    "    record = record.rstrip()\n",
    "    all_values = record.split(',')\n",
    "    # we need to scale inputs so, they would be small. \n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # now we need the targets. all_values[0] represents actual number\n",
    "    targets = np.zeros(output_nodes) + 0.01 # created [0.01, 0.01... 0.01]\n",
    "    # one of targets should correspond to our number. For example, if all_values[0]=='1',\n",
    "    # then targets = [0.01, 0.99, 0.01 ... 0.01]\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    rotated_plus_10 = n.rotate_inputs(inputs, 10.0)     # \"inputs\" rotated plus 10 degress\n",
    "    rotated_minus_10 = n.rotate_inputs(inputs, -10.0)    # \"inputs\" rotated minus 10 degress \n",
    "    n.train(rotated_plus_10, targets)\n",
    "    n.train(rotated_minus_10, targets)\n",
    "    record_count += 3\n",
    "end_training_time = time.time()\n",
    "\n",
    "print('Training took: {} seconds'.format(end_training_time - start_training_time))\n",
    "print('Total number of records with which we tratined NN: {}'.format(record_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mnist_test.csv', 'r') as f:\n",
    "        test_data_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct guess percentage:  0.9801\n",
      "Number of correctly guessed labels: 9801\n",
      "Size of test data: 10000 records\n"
     ]
    }
   ],
   "source": [
    "# Calulating correct guess percentage:\n",
    "scorecard = []\n",
    "for record in test_data_list:\n",
    "    record = record.rstrip()\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0])\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "    outputs = n.query(inputs)\n",
    "    label = np.argmax(outputs)\n",
    "    if label == correct_label:\n",
    "        scorecard.append(1)\n",
    "    else: \n",
    "        scorecard.append(0)\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print('Correct guess percentage: ', scorecard_array.sum() / scorecard_array.size)\n",
    "print('Number of correctly guessed labels:', scorecard_array.sum())\n",
    "print('Size of test data: {} records'.format(scorecard_array.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights to file: \"epoch5_250hidden_nodes_rotated6.npz\"\n"
     ]
    }
   ],
   "source": [
    "# n.print_weights()\n",
    "n.save_weights_to_file('epoch5_250hidden_nodes_rotated6.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
